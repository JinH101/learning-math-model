# 目的
这次学习的目的是加深对数据处理的理解，以往的学习大多是模仿现有的步骤、方法，并不懂为何要这么做。这次想要梳理、衔接各种知识，形成框架。

# 内容结构
摘录启发我形成理解的内容，写出自己的理解，或者提出问题。如果时间充裕直接做出回答，如果来不及，过后再补充。

# 收获到的理解
### 6.1.1 数据与多模态
- 计算机可以处理人类能感知和认知的各种信息 ——> 计算机模拟人类世界的step 1，把人类了解到的信息变成数据
- 不同的信息形式叫做模态，多模态大模型中的”多模态“指的就是模型可以使用描述同一事物的不同模态的数据进行联合建模 ——> 是受人类处理信息启发吗，如何实现联合？

### 6.1.2 数据与大数据
- 数据的体量是选择数据研究方法的一个衡量 ——> 还没有那么清晰的数值标准，要找找例子；其他衡量还有啥？

### 6.1.3 数据科学的研究对象
- 数学建模需要数学基础，也需要计算机基础，但在解决实际工程问题的时候需要特定的工程背景。此三者缺一不可。——> 缺少工程背景是我面对题目表述时望而生畏的一个原因，还有一个是对数学和计算机理论的理解还不够，目前是觉得如果有更好的理解，会有更好的problem solving能力。

### 6.2.1 为什么需要数据预处理
- 数据和特征决定了效果的上限，而模型和算法只是逼近这个上限而已 ——> 那我是理解反了，我以为方法更重要，重要到可以跨越数据的缺陷和陷阱

- 如果表格中列数超过了行数的1/2就可以说是有些稀疏了，如果列数是行数的3倍那它就是严重稀疏的数据。——> 稀疏的确切数值定义

- 连续属性和离散属性的处理方法是截然不同的。——> 留意

### 6.2.2 使用pandas处理数据的基础
- 缺失数据的处理基于缺失率：如果存在缺失的数据项（数表一行称作一个数据项）占比较少（大概5%以内）这个时候如果问题允许可以把行删掉。如果缺失率稍微高一点（5%-20%）左右就可以使用填充、插值的方法去处
理，有关插值的方法我们会在下一节探讨，而填充方法包括常数填充、均值填充等方法；如果缺失率还高一些（20%-40%）那么就需要用预测方法例如机器学习去填充缺失数据了；但如果一行数据有50%以上都是缺失的，如果条件允许，我们可以把这一列都删掉（当然凡事都有例外，见机行事）。 ——> 缺失数据处理的不同方法的数值依据

### 6.2.3 数据的规约
- 数据分布中量纲影响和数值差异可能会比较大，比如min-max规约是为了消除量纲影响，所有的属性都被规约到[0,1]的范围内，数据的偏差不会那么大。 ——> 短暂查询还是没太理解量纲这个概念，再看看


### 6.3.2 假设检验
- 假设检验是统计分析中重要的一环，它贯穿着统计分析的所有环节。根据样本信息与已知信息，对一个描述总体性质的命题进行“是或否”的检验与回答，就是假设检验的本质。即：假设检验验证的不是样本本身的性质，而是样本所在总体的性质。——> 数值与推理的结合。

- 正态性检验：于参数检验比非参数检验更灵敏，因此一旦数据是正态分布的，我们应该使用参数检验，此时对数据进行正态性检验就非常有必要了。——> 常看到用正态分布做初步分析，看起来没啥原因像是孤立的一步，原来是这个用意

- 正态性检验的方法比如可视化判断-正态分布概率图；Shapiro-Wilk检验；D'Agostino's K-squared检验。实际应用中，由于数据的复杂性，仅使用一种方法判断正态性有可能产生一定的误差，因此我们通常同时使用多种方法进行判断。如果不同方法得出的结论不同，此时就需要仔细观察数据的特征，寻找结果不一致的原因。——> 对数据分析方法的信任程度


# 未完待续

### 


### 


### 


### 


### 


### 

